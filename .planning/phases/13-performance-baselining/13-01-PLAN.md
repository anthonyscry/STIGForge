---
phase: 13-performance-baselining
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj
  - benchmarks/STIGForge.Benchmarks/Program.cs
  - benchmarks/STIGForge.Benchmarks/BenchmarkConfig.cs
  - src/STIGForge.Infrastructure/Telemetry/PerformanceInstrumenter.cs
  - STIGForge.sln
autonomous: true
requirements: [OBSV-03]
user_setup: []

must_haves:
  truths:
    - "PerformanceInstrumenter records mission duration and startup time metrics"
    - "BenchmarkDotNet project compiles and runs basic benchmark scaffolding"
    - "Benchmarks project is part of solution and discoverable via dotnet run"
  artifacts:
    - path: "benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj"
      provides: "Benchmark project definition with BenchmarkDotNet reference"
    - path: "benchmarks/STIGForge.Benchmarks/Program.cs"
      provides: "BenchmarkSwitcher entry point"
    - path: "src/STIGForge.Infrastructure/Telemetry/PerformanceInstrumenter.cs"
      provides: "Performance metrics collection using System.Diagnostics.Metrics"
  key_links:
    - from: "PerformanceInstrumenter"
      to: "MissionTracingService"
      via: "same telemetry namespace"
      pattern: "STIGForge.Infrastructure.Telemetry"
---

<objective>
Create the performance measurement infrastructure including PerformanceInstrumenter service and BenchmarkDotNet project scaffolding.

Purpose: Establish foundation for reproducible performance baselines without requiring external dependencies beyond BenchmarkDotNet.
Output: Working BenchmarkDotNet project and PerformanceInstrumenter service integrated with existing telemetry infrastructure.
</objective>

<execution_context>
@/home/anthonyscry/.claude/get-shit-done/workflows/execute-plan.md
@/home/anthonyscry/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-performance-baselining/13-RESEARCH.md

# Existing telemetry infrastructure (from Phase 12)
@src/STIGForge.Infrastructure/Telemetry/MissionTracingService.cs
@src/STIGForge.Infrastructure/Telemetry/ActivitySourceNames.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PerformanceInstrumenter service</name>
  <files>src/STIGForge.Infrastructure/Telemetry/PerformanceInstrumenter.cs</files>
  <action>
Create PerformanceInstrumenter service in STIGForge.Infrastructure/Telemetry/ that uses System.Diagnostics.Metrics (built-in .NET 8, no new packages) to collect performance metrics.

Implementation requirements:
1. Create static Meter named "STIGForge.Performance"
2. Create Counter for missions completed (tagged by mission.type)
3. Create Histogram for mission duration in milliseconds (tagged by mission.type)
4. Create Histogram for startup duration in milliseconds (tagged by startup.cold boolean)
5. Create Counter for rules processed

Methods:
- RecordMissionCompleted(string missionType, int ruleCount, double durationMs)
- RecordStartupTime(double durationMs, bool isColdStart)

Follow the pattern established by MissionTracingService - use null-safe operations, follow existing namespace conventions. Do NOT use OpenTelemetry SDK - use built-in System.Diagnostics.Metrics only.
  </action>
  <verify>
    <command>dotnet build src/STIGForge.Infrastructure/STIGForge.Infrastructure.csproj</command>
    <expect>Build succeeds with no errors</expect>
  </verify>
  <done>PerformanceInstrumenter compiles and exposes RecordMissionCompleted and RecordStartupTime methods using System.Diagnostics.Metrics</done>
</task>

<task type="auto">
  <name>Task 2: Create BenchmarkDotNet project</name>
  <files>
    benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj
    benchmarks/STIGForge.Benchmarks/Program.cs
    benchmarks/STIGForge.Benchmarks/BenchmarkConfig.cs
    STIGForge.sln
  </files>
  <action>
Create a new BenchmarkDotNet console project for performance benchmarks.

1. Create directory: benchmarks/STIGForge.Benchmarks/

2. Create STIGForge.Benchmarks.csproj with:
   - Target framework: net8.0
   - Implicit usings enabled
   - Nullable enabled
   - PackageReference: BenchmarkDotNet version 0.15.2

3. Create Program.cs with BenchmarkSwitcher entry point:
   - Empty switcher initially (benchmarks added in subsequent plans)
   - Include help text comment showing how to run benchmarks
   - Use: dotnet run -c Release --filter "*"

4. Create BenchmarkConfig.cs with job configuration:
   - SimpleJob with RuntimeMoniker.Net80
   - MemoryDiagnoser attribute support
   - MinColumn, MaxColumn, MeanColumn, MedianColumn exporters

5. Add project to STIGForge.sln using dotnet sln add command

Do NOT create actual benchmarks yet - just the scaffolding. Do NOT add project references to source projects yet - that comes in subsequent plans.
  </action>
  <verify>
    <command>dotnet build benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj -c Release</command>
    <expect>Build succeeds with no errors</expect>
  </verify>
  <done>BenchmarkDotNet project compiles in Release mode, is part of solution, and can be run with dotnet run -c Release</done>
</task>

</tasks>

<verification>
- PerformanceInstrumenter exists in src/STIGForge.Infrastructure/Telemetry/
- BenchmarkDotNet project exists in benchmarks/STIGForge.Benchmarks/
- Both projects compile successfully
- BenchmarkDotNet version 0.15.2 referenced
- Project added to STIGForge.sln
</verification>

<success_criteria>
- PerformanceInstrumenter records metrics using System.Diagnostics.Metrics
- BenchmarkDotNet project scaffolding ready for benchmark implementation
- No external NuGet packages added to Infrastructure project (uses built-in .NET 8)
- BenchmarkDotNet 0.15.2 installed in benchmarks project only
</success_criteria>

<output>
After completion, create `.planning/phases/13-performance-baselining/13-01-SUMMARY.md`
</output>
