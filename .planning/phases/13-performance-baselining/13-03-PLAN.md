---
phase: 13-performance-baselining
plan: 03
type: execute
wave: 2
depends_on: [13-01]
files_modified:
  - benchmarks/STIGForge.Benchmarks/MissionBenchmarks.cs
  - benchmarks/STIGForge.Benchmarks/ScaleBenchmarks.cs
  - benchmarks/STIGForge.Benchmarks/TestData/GenerateTestBundle.cs
  - benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj
autonomous: true
requirements: [PERF-03, PERF-04]
user_setup: []

must_haves:
  truths:
    - "Mission duration can be measured for Build, Apply, Verify, Prove phases"
    - "Scale testing validates 10K+ rule processing without out-of-memory errors"
    - "Test bundles can be generated programmatically with configurable rule counts"
  artifacts:
    - path: "benchmarks/STIGForge.Benchmarks/MissionBenchmarks.cs"
      provides: "Mission phase duration benchmarks"
      exports: ["BuildPhase", "ApplyPhase", "VerifyPhase", "ProvePhase"]
    - path: "benchmarks/STIGForge.Benchmarks/ScaleBenchmarks.cs"
      provides: "Scale testing with varying rule counts"
      contains: "Params(100, 1000, 10000)"
    - path: "benchmarks/STIGForge.Benchmarks/TestData/GenerateTestBundle.cs"
      provides: "Synthetic test bundle generation"
  key_links:
    - from: "MissionBenchmarks"
      to: "BundleOrchestrator"
      via: "service provider and DI"
      pattern: "GetRequiredService"
    - from: "ScaleBenchmarks"
      to: "MissionBenchmarks"
      via: "shared test bundle generation"
      pattern: "GenerateTestBundle"
---

<objective>
Implement mission duration benchmarks and scale testing to establish baselines for PERF-03 (mission durations) and PERF-04 (10K+ rule scale validation).

Purpose: Measure how long each mission phase takes at different scales and validate that the system can handle 10K+ rules without running out of memory.
Output: MissionBenchmarks and ScaleBenchmarks that produce duration measurements at 100, 1K, and 10K rule scales.
</objective>

<execution_context>
@/home/anthonyscry/.claude/get-shit-done/workflows/execute-plan.md
@/home/anthonyscry/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-performance-baselining/13-RESEARCH.md
@.planning/phases/13-performance-baselining/13-01-SUMMARY.md

# Benchmark infrastructure from 13-01
@benchmarks/STIGForge.Benchmarks/BenchmarkConfig.cs

# Existing patterns for test data
@tests/STIGForge.UnitTests/fixtures/compat-stig-baseline-xccdf.xml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test bundle generator</name>
  <files>
    benchmarks/STIGForge.Benchmarks/TestData/GenerateTestBundle.cs
    benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj
  </files>
  <action>
Create a test bundle generator that produces synthetic STIG data with configurable rule counts.

Implementation:
1. Create TestData directory under benchmarks project
2. Create GenerateTestBundle.cs with static methods:
   - GenerateXccdfContent(int ruleCount): Creates XCCDF XML content with N rules
   - CreateTestBundle(int ruleCount, string outputDir): Creates a complete bundle directory structure

3. Generated XCCDF should include:
   - Proper XCCDF namespace and structure
   - Each rule with: RuleId, VulnId, Title, Severity, CheckText, FixText
   - Realistic content patterns (not just "Rule1", "Rule2")

4. Bundle structure should include:
   - Manifest.json with metadata
   - Apply/ directory (minimal content)
   - Rules stored in format consumable by BundleBuilder

5. Add necessary project references to benchmarks csproj:
   - STIGForge.Core (for ControlRecord, models)
   - STIGForge.Build (for bundle structure)

NOTE: This generates synthetic data since Chrome STIG may not be available. The generated data should exercise XML parsing and processing paths realistically.
  </action>
  <verify>
    <command>dotnet build benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj -c Release</command>
    <expect>Build succeeds with no errors</expect>
  </verify>
  <done>GenerateTestBundle creates test bundles with configurable rule counts, benchmarks project has required references</done>
</task>

<task type="auto">
  <name>Task 2: Create MissionBenchmarks</name>
  <files>
    benchmarks/STIGForge.Benchmarks/MissionBenchmarks.cs
    benchmarks/STIGForge.Benchmarks/Program.cs
  </files>
  <action>
Create MissionBenchmarks.cs for measuring mission phase durations.

1. Create MissionBenchmarks class with:
   - [MemoryDiagnoser] attribute
   - [SimpleJob(RuntimeMoniker.Net80, launchCount: 1, warmupCount: 3, iterationCount: 10)]
   - [MinColumn, MaxColumn, MeanColumn, MedianColumn] attributes
   - [Params(100, 1000, 10000)] for RuleCount

2. GlobalSetup:
   - Build test service provider with in-memory database
   - Generate test bundles at 100, 1K, 10K scales
   - Store bundle paths for benchmarks

3. Benchmarks (measure each phase):
   - BuildPhase: Measure BundleBuilder.ExecuteAsync
   - ApplyPhase: Placeholder - notes that Apply requires PowerShell/system context
   - VerifyPhase: Measure VerificationWorkflowService with mock runners
   - ProvePhase: Measure EmassExporter.ExportAsync

4. GlobalCleanup:
   - Dispose service provider
   - Clean up test bundle directories

5. Update Program.cs BenchmarkSwitcher to include MissionBenchmarks

IMPORTANT: ApplyPhase should be marked as placeholder with [Benchmark(Baseline = false)] and comment explaining that real Apply requires PowerShell and system context. For baselining purposes, focus on Build, Verify (mocked), and Prove phases.
  </action>
  <verify>
    <command>dotnet build benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj -c Release</command>
    <expect>Build succeeds with no errors</expect>
  </verify>
  <done>MissionBenchmarks compiles with Build, Apply (placeholder), Verify, Prove benchmarks at multiple scales</done>
</task>

<task type="auto">
  <name>Task 3: Create ScaleBenchmarks for 10K+ validation</name>
  <files>
    benchmarks/STIGForge.Benchmarks/ScaleBenchmarks.cs
    benchmarks/STIGForge.Benchmarks/Program.cs
  </files>
  <action>
Create ScaleBenchmarks.cs specifically for validating 10K+ rule processing without OOM.

1. Create ScaleBenchmarks class with:
   - [MemoryDiagnoser] attribute (critical for OOM detection)
   - [SimpleJob(RuntimeMoniker.Net80, launchCount: 1, warmupCount: 1, iterationCount: 3)]
   - [Params(100, 1000, 5000, 10000, 15000)] for RuleCount (push beyond 10K target)

2. Benchmarks:
   - LoadRules: Parse and load XCCDF rules into memory (tests XML parsing at scale)
   - BuildBundleAtScale: Full bundle build at scale (tests memory pressure)
   - ProcessInMemory: Process rules without file I/O (isolates memory handling)

3. Each benchmark should:
   - Report allocated memory via MemoryDiagnoser
   - Pass if completes without OutOfMemoryException
   - Document GC behavior in output

4. Update Program.cs BenchmarkSwitcher to include ScaleBenchmarks

5. Add assertion in benchmarks: If memory exceeds 2GB during 10K rule processing, log warning (but don't fail - this documents the baseline)

CRITICAL: These benchmarks validate PERF-04 requirement. Success = no OOM at 10K+ rules. Document actual memory usage for baseline.
  </action>
  <verify>
    <command>dotnet build benchmarks/STIGForge.Benchmarks/STIGForge.Benchmarks.csproj -c Release</command>
    <expect>Build succeeds with no errors</expect>
  </verify>
  <done>ScaleBenchmarks compiles with 100, 1K, 5K, 10K, 15K rule scale tests, MemoryDiagnoser enabled for OOM detection</done>
</task>

</tasks>

<verification>
- MissionBenchmarks.cs exists with Build, Verify, Prove benchmarks
- ScaleBenchmarks.cs exists with 10K+ rule scale tests
- GenerateTestBundle creates synthetic bundles programmatically
- All benchmarks compile in Release mode
- MemoryDiagnoser enabled on all benchmarks
- BenchmarkSwitcher updated with all new benchmarks
</verification>

<success_criteria>
- Mission duration benchmarks measure Build, Verify (mocked), Prove phases
- Scale benchmarks test 100, 1K, 5K, 10K, 15K rule processing
- MemoryDiagnoser captures allocation data for all scale tests
- Apply phase documented as placeholder (requires system context)
- Test bundle generation creates realistic synthetic data
</success_criteria>

<output>
After completion, create `.planning/phases/13-performance-baselining/13-03-SUMMARY.md`
</output>
